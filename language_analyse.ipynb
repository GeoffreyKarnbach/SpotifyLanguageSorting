{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALYSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce a smaller dataset with only English, German and French (no other languages necessary for our purpose, can easily be extended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = [\"English\", \"German\", \"French\"]\n",
    "\n",
    "df = pd.read_csv('Data/languages.csv')\n",
    "\n",
    "reduced_df = df[df['Language'].isin(languages)]\n",
    "reduced_df.to_csv('Data/minimal_languages.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export french only into single csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "french_df = df[df['Language'].isin([\"French\"])]\n",
    "french_df.to_csv('Data/french.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export german only into single csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "german_df = df[df['Language'].isin([\"German\"])]\n",
    "german_df.to_csv('Data/german.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export english only into single csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_df = df[df['Language'].isin([\"English\"])]\n",
    "english_df.to_csv('Data/english.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common french statistics regarding data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1014\n",
      "23260\n",
      "124921\n",
      "5.370636285468616\n"
     ]
    }
   ],
   "source": [
    "french_df = pd.read_csv('Data/french.csv', encoding='utf-8')\n",
    "\n",
    "fr_array_of_word_arrays = [word.replace(u'\\xa0', u' ').split(\" \") for word in french_df['Text']]\n",
    "fr_number_of_sentences = len(fr_array_of_word_arrays)\n",
    "fr_number_of_words = sum([len(item) for item in fr_array_of_word_arrays])\n",
    "fr_number_of_letters = sum(sum([len(word) for word in sentence]) for sentence in fr_array_of_word_arrays)\n",
    "fr_average_word_length = fr_number_of_letters / fr_number_of_words\n",
    "\n",
    "print(fr_number_of_sentences)\n",
    "print(fr_number_of_words)\n",
    "print(fr_number_of_letters)\n",
    "print(fr_average_word_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common english statistics regarding data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1385\n",
      "30382\n",
      "160611\n",
      "5.286386676321506\n"
     ]
    }
   ],
   "source": [
    "english_df = pd.read_csv('Data/english.csv', encoding='utf-8')\n",
    "\n",
    "eng_array_of_word_arrays = [word.replace(u'\\xa0', u' ').split(\" \") for word in english_df['Text']]\n",
    "eng_number_of_sentences = len(eng_array_of_word_arrays)\n",
    "eng_number_of_words = sum([len(item) for item in eng_array_of_word_arrays])\n",
    "eng_number_of_letters = sum(sum([len(word) for word in sentence]) for sentence in eng_array_of_word_arrays)\n",
    "eng_average_word_length = eng_number_of_letters / eng_number_of_words\n",
    "\n",
    "print(eng_number_of_sentences)\n",
    "print(eng_number_of_words)\n",
    "print(eng_number_of_letters)\n",
    "print(eng_average_word_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common german statistics regarding data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470\n",
      "5927\n",
      "29653\n",
      "5.003036949552894\n"
     ]
    }
   ],
   "source": [
    "german_df = pd.read_csv('Data/german.csv', encoding='utf-8')\n",
    "\n",
    "ger_array_of_word_arrays = [word.replace(u'\\xa0', u' ').split(\" \") for word in german_df['Text']]\n",
    "ger_number_of_sentences = len(ger_array_of_word_arrays)\n",
    "ger_number_of_words = sum([len(item) for item in ger_array_of_word_arrays])\n",
    "ger_number_of_letters = sum(sum([len(word) for word in sentence]) for sentence in ger_array_of_word_arrays)\n",
    "ger_average_word_length = ger_number_of_letters / ger_number_of_words\n",
    "\n",
    "print(ger_number_of_sentences)\n",
    "print(ger_number_of_words)\n",
    "print(ger_number_of_letters)\n",
    "print(ger_average_word_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of typical attributes, allowing direct identification of a language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Special character (french specific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4138\n",
      "3.31 %\n"
     ]
    }
   ],
   "source": [
    "fr_special_char = [\"é\", \"è\", \"ê\", \"à\", \"â\", \"ù\", \"ô\", \"ç\"]\n",
    "\n",
    "fr_occurence = 0\n",
    "\n",
    "for sentence in fr_array_of_word_arrays:\n",
    "    for word in sentence:\n",
    "        for char in word:\n",
    "            if char.lower() in fr_special_char:\n",
    "                fr_occurence += 1\n",
    "\n",
    "fr_occurence_rate = fr_occurence / fr_number_of_letters\n",
    "\n",
    "print(fr_occurence)\n",
    "print(f\"{round(fr_occurence_rate*100, 2)} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse occurence rate of special character in german and english (should be very low for attribute to have high entropy value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English\n",
      "5\n",
      "0.0 %\n",
      "\n",
      "German\n",
      "0\n",
      "0.0 %\n"
     ]
    }
   ],
   "source": [
    "english_df = pd.read_csv('Data/english.csv', encoding='utf-8')\n",
    "german_df = pd.read_csv('Data/german.csv', encoding='utf-8')\n",
    "\n",
    "eng_occurence = 0\n",
    "ger_occurence = 0\n",
    "\n",
    "for sentence in eng_array_of_word_arrays:\n",
    "    for word in sentence:\n",
    "        for char in word:\n",
    "            if char.lower() in fr_special_char:\n",
    "                eng_occurence += 1\n",
    "\n",
    "for sentence in ger_array_of_word_arrays:\n",
    "    for word in sentence:\n",
    "        for char in word:\n",
    "            if char.lower() in fr_special_char:\n",
    "                ger_occurence += 1\n",
    "\n",
    "eng_occurence_rate = eng_occurence / eng_number_of_letters\n",
    "ger_occurence_rate = ger_occurence / ger_number_of_letters\n",
    "\n",
    "print(\"English\")\n",
    "print(eng_occurence)\n",
    "print(f\"{round(eng_occurence_rate*100, 2)} %\\n\")\n",
    "\n",
    "print(\"German\")\n",
    "print(ger_occurence)\n",
    "print(f\"{round(ger_occurence_rate*100, 2)} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very low values (5 for english and 0 for german), therefore the attribute \"contains_spec_char\" is a good indication if it is french (not containing does not imply that it is not french though, as occurence rate is quite low ~3.28% only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Special character (german specific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "490\n",
      "1.65 %\n"
     ]
    }
   ],
   "source": [
    "ger_special_char = [\"ä\", \"ö\", \"ü\", \"ß\"]\n",
    "\n",
    "ger_occurence = 0\n",
    "\n",
    "for sentence in ger_array_of_word_arrays:\n",
    "    for word in sentence:\n",
    "        for char in word:\n",
    "            if char.lower() in ger_special_char:\n",
    "                ger_occurence += 1\n",
    "\n",
    "ger_occurence_rate = ger_occurence / ger_number_of_letters\n",
    "\n",
    "print(ger_occurence)\n",
    "print(f\"{round(ger_occurence_rate*100, 2)} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse occurence rate of special character in french and english (should be very low for attribute to have high entropy value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English\n",
      "3\n",
      "0.0 %\n",
      "\n",
      "French\n",
      "2\n",
      "0.0 %\n"
     ]
    }
   ],
   "source": [
    "english_df = pd.read_csv('Data/english.csv', encoding='utf-8')\n",
    "french_df = pd.read_csv('Data/german.csv', encoding='utf-8')\n",
    "\n",
    "eng_occurence = 0\n",
    "fr_occurence = 0\n",
    "\n",
    "for sentence in eng_array_of_word_arrays:\n",
    "    for word in sentence:\n",
    "        for char in word:\n",
    "            if char.lower() in ger_special_char:\n",
    "                eng_occurence += 1\n",
    "\n",
    "for sentence in fr_array_of_word_arrays:\n",
    "    for word in sentence:\n",
    "        for char in word:\n",
    "            if char.lower() in ger_special_char:\n",
    "                fr_occurence += 1\n",
    "\n",
    "eng_occurence_rate = eng_occurence / eng_number_of_letters\n",
    "fr_occurence_rate = fr_occurence / fr_number_of_letters\n",
    "\n",
    "print(\"English\")\n",
    "print(eng_occurence)\n",
    "print(f\"{round(eng_occurence_rate*100, 2)} %\\n\")\n",
    "\n",
    "print(\"French\")\n",
    "print(fr_occurence)\n",
    "print(f\"{round(fr_occurence_rate*100, 2)} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The english and french language only have a very minimalistic usage of the german \"special\" character (3 for english and 2 for french), therefore an occurence of one of the german special characters are a very good indication, that the language is german."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can conclude, that the usage of one of the french special characters ([\"é\", \"è\", \"ê\", \"à\", \"â\", \"ù\", \"ô\", \"ç\"]) or the usage of one of the german special characters ([\"ä\", \"ö\", \"ü\", \"ß\"]), both non case sensitive, are a very good indicator that the language is french/german (depending on the character)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The french special character only had an occurence rate of ~3.28 %, the german special character only 1.65%.\n",
    "Therefore, we clearly need further attributes to determine which language a text sample is, in case no special characters occur (either intentionally or unintentionally)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More global language analysis (no direct identification)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
